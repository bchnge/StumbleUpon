{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import nltk\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTrain = pd.read_csv('../data/train.tsv',sep = '\\t')\n",
      "dfTest = pd.read_csv('../data/test.tsv', sep = '\\t')\n",
      "\n",
      "df = dfTrain.append(dfTest,ignore_index=True)\n",
      "\n",
      "df['setType'] = 'training'\n",
      "df['setType'][np.isnan(df.label)] = 'test'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extract features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getBoilerPlateText(text, obj = 'title'):    \n",
      "    try:\n",
      "        result = json.loads(text)[obj].encode('utf-8').strip()    \n",
      "    except:  # if there is no title, put in blank\n",
      "        result = ''\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boilerPlateTitles = df.boilerplate.apply(getBoilerPlateText,obj = 'title')\n",
      "boilerPlateBodies = df.boilerplate.apply(getBoilerPlateText,obj =  'body')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "\n",
      "# Vectorizer will by default remove punctuation and convert to lower case. We just need to strip the stop words before training our classifier.\n",
      "vectorizer = TfidfVectorizer(min_df=2,stop_words='english',binary=False, analyzer='word', use_idf = True, smooth_idf = True, sublinear_tf = True) # use binary option to check for instances instead of summing instances\n",
      "bodyVect = vectorizer.fit_transform(boilerPlateBodies)\n",
      "titleVect = vectorizer.fit_transform(boilerPlateTitles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def countText(text, pattern, relative = True):\n",
      "    import re\n",
      "    result = len(re.findall(pattern, text))\n",
      "    if relative == True:\n",
      "        result = result / np.double(countWords(text))\n",
      "    if text == '':\n",
      "        result = 0\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def countWords(text):\n",
      "    import nltk\n",
      "    if text == '':\n",
      "        result = 0\n",
      "    else: \n",
      "        result = len(nltk.word_tokenize(text))\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyTerms = ['\\,',\n",
      "            '\\!',\n",
      "            'butter',\n",
      "            'water',\n",
      "            'cup',\n",
      "            'degree',\n",
      "            'recipe'\n",
      "            'comment',\n",
      "            'email',\n",
      "            'contact',\n",
      "            '[0-9]{4}',\n",
      "            '\\|',\n",
      "            '\\d',\n",
      "            '@',\n",
      "            'calories',\n",
      "            'sign?in',\n",
      "            'log?in',\n",
      "            'register'\n",
      "            ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textFeatures = pd.DataFrame(index = df.index)\n",
      "for term in keyTerms:\n",
      "    textFeatures['bpBodyContains_' + term] = boilerPlateBodies.apply(countText, pattern = term, relative = True)\n",
      "    textFeatures['bpTitleContains_' + term] = boilerPlateTitles.apply(countText, pattern = term, relative = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getUrlDomain(url):\n",
      "    import urlparse\n",
      "    import re\n",
      "    parsed = urlparse.urlparse(url)\n",
      "    domain = re.sub('^www\\.', '', parsed.netloc).split('.')\n",
      "    result = domain[len(domain)-1]\n",
      "    return result\n",
      "\n",
      "def getName(url):\n",
      "    import urlparse\n",
      "    import re\n",
      "    parsed = urlparse.urlparse(url)\n",
      "    domain = re.sub('^www\\.', '', parsed.netloc).split('.')\n",
      "    result = domain[0]\n",
      "    return result\n",
      "\n",
      "def countPaths(url):\n",
      "    import urlparse\n",
      "    import re\n",
      "    parsed = urlparse.urlparse(url)\n",
      "    domain = re.findall('\\/',parsed.path)\n",
      "    return len(domain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "domains = df.url.apply(getUrlDomain)\n",
      "webNames = df.url.apply(getName)\n",
      "numPaths = df.url.apply(countPaths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "domains_df = pd.get_dummies(domains, prefix = 'DUM')\n",
      "webNames_df = pd.get_dummies(webNames, prefix = 'DUM')\n",
      "alchemyCategories_df = pd.get_dummies(df.alchemy_category, prefix = 'DUM')\n",
      "numPaths_df = pd.get_dummies(numPaths, prefix = 'DUM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "originalFeatureList =['avglinksize','commonlinkratio_1','commonlinkratio_2','commonlinkratio_3','commonlinkratio_4', \n",
      "           'compression_ratio','embed_ratio','frameTagRatio', 'framebased', 'hasDomainLink', 'html_ratio', 'image_ratio', \n",
      "           'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks',\n",
      "           'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio']\n",
      "\n",
      "originalFeatures = df[originalFeatureList]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import TruncatedSVD\n",
      "\n",
      "titleDecomposed = TruncatedSVD(random_state = 123, n_components = 10).fit_transform(titleVect)\n",
      "bodyDecomposed = TruncatedSVD(random_state = 123, n_components = 50).fit_transform(bodyVect)\n",
      "\n",
      "textDecomposed = np.hstack([titleDecomposed,bodyDecomposed])\n",
      "textDecomposed_training = textDecomposed[df.setType == 'training']\n",
      "textDecomposed_test = textDecomposed[df.setType == 'test']\n",
      "\n",
      "\n",
      "# used for estimating alch cats\n",
      "titleDecomposed2 = TruncatedSVD(random_state = 123, n_components = 100).fit_transform(titleVect)\n",
      "bodyDecomposed2 = TruncatedSVD(random_state = 123, n_components = 500).fit_transform(bodyVect)\n",
      "textDecomposed2 = np.hstack([titleDecomposed2,bodyDecomposed2])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construct Training and Test Data\n",
      "originalFeatures_training = originalFeatures[df.setType == 'training']\n",
      "textFeatures_training = textFeatures[df.setType == 'training']\n",
      "domains_training = domains_df[df.setType == 'training']\n",
      "webNames_training = webNames_df[df.setType == 'training']\n",
      "numPaths_training = numPaths_df[df.setType == 'training']\n",
      "alchemyCategories_training = alchemyCategories_df[df.setType == 'training']\n",
      "\n",
      "Y = df[df.setType == 'training'].label\n",
      "X = np.concatenate((originalFeatures_training.values, textFeatures_training, numPaths_training,\n",
      "                    domains_training.values, webNames_training.values,alchemyCategories_training.values), 1)\n",
      "X[X == '?'] = 0\n",
      "\n",
      "\n",
      "# Construct ALTERNATE Training and Test Data\n",
      "X_alt = np.hstack([X, textDecomposed_training])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "originalFeatures_test = originalFeatures[df.setType == 'test']\n",
      "textFeatures_test = textFeatures[df.setType == 'test']\n",
      "domains_test = domains_df[df.setType == 'test']\n",
      "webNames_test = webNames_df[df.setType == 'test']\n",
      "numPaths_test = numPaths_df[df.setType == 'test']\n",
      "alchemyCategories_test = alchemyCategories_df[df.setType == 'test']\n",
      "\n",
      "X_Test = np.concatenate((originalFeatures_test.values, textFeatures_test, numPaths_test,\n",
      "                    domains_test.values, webNames_test.values,alchemyCategories_test.values), 1)\n",
      "X_Test[X_Test == '?'] = 0\n",
      "\n",
      "X_Test_alt = np.hstack([X_Test, textDecomposed_test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = pd.DataFrame(df[df.setType == 'test'].urlid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train chosen classifier and predict on test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alch_cat_training = df[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')].alchemy_category\n",
      "predictors = textDecomposed2[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')]\n",
      "alch_cats = alch_cat_training.unique()\n",
      "\n",
      "i = 0\n",
      "for item in alch_cats:\n",
      "    alch_cat_training[alch_cat_training == item] = i\n",
      "    i += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf2 = BernoulliNB(alpha = 0.5, fit_prior=True)\n",
      "clf2.fit(predictors, alch_cat_training.astype(np.int))\n",
      "estAlchCat = clf2.predict(textDecomposed2)\n",
      "estAlchCat[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')] = alch_cat_training[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')]\n",
      "\n",
      "alchemyCategories2_df = pd.get_dummies(estAlchCat, prefix = 'DUM')\n",
      "alchemyCategories2_training = alchemyCategories2_df[df.setType == 'training']\n",
      "alchemyCategories2_test = alchemyCategories2_df[df.setType == 'test']\n",
      "\n",
      "X_alt_2 = X = np.hstack([originalFeatures_training.values, textFeatures_training, numPaths_training,\n",
      "                    domains_training.values, webNames_training.values,alchemyCategories2_training.values, textDecomposed_training])\n",
      "\n",
      "X_Test_2 = np.hstack([originalFeatures_test.values, textFeatures_test, numPaths_test,\n",
      "                    domains_test.values, webNames_test.values,alchemyCategories2_test.values, textDecomposed_test])\n",
      "\n",
      "X_alt_2[X_alt_2 == '?'] = 0\n",
      "X_Test_2[X_Test_2 == '?'] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = AdaBoostClassifier(RandomForestClassifier(criterion = 'gini',random_state = 123,\n",
      "                                 min_samples_leaf = 2, min_samples_split = 6, n_estimators = 300))\n",
      "\n",
      "rf.fit(X_alt_2, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "AdaBoostClassifier(algorithm='SAMME.R',\n",
        "          base_estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=2, min_samples_split=6,\n",
        "            n_estimators=300, n_jobs=1, oob_score=False, random_state=123,\n",
        "            verbose=0),\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr =  LogisticRegression(random_state = 123, penalty = 'l1', C = 1)\n",
      "lr.fit(X_alt_2, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=123, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ada = AdaBoostClassifier()\n",
      "ada.fit(X_alt_2, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "AdaBoostClassifier(algorithm='SAMME.R',\n",
        "          base_estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=1, max_features=None, min_density=None,\n",
        "            min_samples_leaf=1, min_samples_split=2, random_state=None,\n",
        "            splitter='best'),\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.lda import LDA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = LDA(n_components=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossVal(lda, X_alt_2.astype(np.float), Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.82467105263157992, 0.80717105263157995, 0.81586988304093466, 0.83338450292397581, 0.8220614035087711, 0.86265024919378341, 0.83148636763412398, 0.83383905013192638, 0.7966578715919076, 0.8022210819527934]\n",
        "0.823001251524\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/bencheng/anaconda/lib/python2.7/site-packages/sklearn/lda.py:162: UserWarning: Variables are collinear\n",
        "  warnings.warn(\"Variables are collinear\")\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "[0.82467105263157992,\n",
        " 0.80717105263157995,\n",
        " 0.81586988304093466,\n",
        " 0.83338450292397581,\n",
        " 0.8220614035087711,\n",
        " 0.86265024919378341,\n",
        " 0.83148636763412398,\n",
        " 0.83383905013192638,\n",
        " 0.7966578715919076,\n",
        " 0.8022210819527934]"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gbm = GradientBoostingClassifier(random_state = 123, n_estimators = 300, max_depth = 6)\n",
      "gbm.fit(X_alt_2, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=6, max_features=None, min_samples_leaf=1,\n",
        "              min_samples_split=2, n_estimators=300, random_state=123,\n",
        "              subsample=1.0, verbose=0)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_rf_2 = rf.predict(X_Test_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_rf_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([ 1.,  0.,  0., ...,  1.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_rf = rf.predict_proba(X_Test_2)[:,1]\n",
      "\n",
      "probs_lr = lr.predict_proba(X_Test_2.astype(np.float))[:,1]\n",
      "probs_gbm = gbm.predict_proba(X_Test_2.astype(np.float))[:,1]\n",
      "probs_ada = ada.predict_proba(X_Test_2.astype(np.float))[:,1]\n",
      "finalPrediction = np.vstack([probs_rf, probs_lr, probs_gbm, probs_rf_2]).mean(0)\n",
      "submission['label'] = finalPrediction.T\n",
      "submission.to_csv('submission_28.csv', index = False, sep = ',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crossVal(clf, X_data, Y_data, NFOLDS = 10): \n",
      "    import sklearn.ensemble as ens\n",
      "    from sklearn import metrics\n",
      "    from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "    skf = StratifiedKFold(Y_data, n_folds = NFOLDS)\n",
      "    auc = []\n",
      "    for train_index, test_index in skf:\n",
      "        x_train, x_test = X_data[train_index], X_data[test_index]\n",
      "        y_train, y_test = Y_data[train_index], Y_data[test_index]\n",
      "        \n",
      "        clf.fit(x_train, y_train)\n",
      "        \n",
      "        try: \n",
      "            probs = clf.predict_proba(x_test)\n",
      "            y_hat = probs[:,1]\n",
      "        except:\n",
      "            y_hat = clf.predict(x_test)\n",
      "        auc.append(metrics.roc_auc_score(y_test, y_hat))\n",
      "    print auc\n",
      "    print np.mean(auc)\n",
      "    return auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}