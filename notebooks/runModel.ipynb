{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import nltk\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTrain = pd.read_csv('../data/train.tsv',sep = '\\t')\n",
      "dfTest = pd.read_csv('../data/test.tsv', sep = '\\t')\n",
      "\n",
      "df = dfTrain.append(dfTest,ignore_index=True)\n",
      "\n",
      "df['setType'] = 'training'\n",
      "df['setType'][np.isnan(df.label)] = 'test'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extract features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getBoilerPlateText(text, obj = 'title'):    \n",
      "    try:\n",
      "        result = json.loads(text)[obj].encode('utf-8').strip()    \n",
      "    except:  # if there is no title, put in blank\n",
      "        result = ''\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boilerPlateTitles = df.boilerplate.apply(getBoilerPlateText,obj = 'title')\n",
      "boilerPlateBodies = df.boilerplate.apply(getBoilerPlateText,obj =  'body')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "\n",
      "# Vectorizer will by default remove punctuation and convert to lower case. We just need to strip the stop words before training our classifier.\n",
      "vectorizer = TfidfVectorizer(min_df=2,stop_words='english',binary=False, analyzer='word', use_idf = True, smooth_idf = True, sublinear_tf = True) # use binary option to check for instances instead of summing instances\n",
      "bodyVect = vectorizer.fit_transform(boilerPlateBodies)\n",
      "titleVect = vectorizer.fit_transform(boilerPlateTitles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def countText(text, pattern, relative = True):\n",
      "    import re\n",
      "    result = len(re.findall(pattern, text))\n",
      "    if relative == True:\n",
      "        result = result / np.double(countWords(text))\n",
      "    if text == '':\n",
      "        result = 0\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def countWords(text):\n",
      "    import nltk\n",
      "    if text == '':\n",
      "        result = 0\n",
      "    else: \n",
      "        result = len(nltk.word_tokenize(text))\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyTerms = ['\\,',\n",
      "            '\\!',\n",
      "            'butter',\n",
      "            'water',\n",
      "            'cup',\n",
      "            'degree',\n",
      "            'recipe'\n",
      "            'comment',\n",
      "            'email',\n",
      "            'contact',\n",
      "            '[0-9]{4}',\n",
      "            '\\|',\n",
      "            '\\d',\n",
      "            '@',\n",
      "            'calories',\n",
      "            'sign?in',\n",
      "            'log?in',\n",
      "            'register'\n",
      "            ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textFeatures = pd.DataFrame(index = df.index)\n",
      "for term in keyTerms:\n",
      "    textFeatures['bpBodyContains_' + term] = boilerPlateBodies.apply(countText, pattern = term, relative = True)\n",
      "    textFeatures['bpTitleContains_' + term] = boilerPlateTitles.apply(countText, pattern = term, relative = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getUrlDomain(url):\n",
      "    import urlparse\n",
      "    import re\n",
      "    parsed = urlparse.urlparse(url)\n",
      "    domain = re.sub('^www\\.', '', parsed.netloc).split('.')\n",
      "    result = domain[len(domain)-1]\n",
      "    return result\n",
      "\n",
      "def getName(url):\n",
      "    import urlparse\n",
      "    import re\n",
      "    parsed = urlparse.urlparse(url)\n",
      "    domain = re.sub('^www\\.', '', parsed.netloc).split('.')\n",
      "    result = domain[0]\n",
      "    return result\n",
      "\n",
      "def countPaths(url):\n",
      "    import urlparse\n",
      "    import re\n",
      "    parsed = urlparse.urlparse(url)\n",
      "    domain = re.findall('\\/',parsed.path)\n",
      "    return len(domain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "domains = df.url.apply(getUrlDomain)\n",
      "webNames = df.url.apply(getName)\n",
      "numPaths = df.url.apply(countPaths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "domains_df = pd.get_dummies(domains, prefix = 'DUM')\n",
      "webNames_df = pd.get_dummies(webNames, prefix = 'DUM')\n",
      "alchemyCategories_df = pd.get_dummies(df.alchemy_category, prefix = 'DUM')\n",
      "numPaths_df = pd.get_dummies(numPaths, prefix = 'DUM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "originalFeatureList =['avglinksize','commonlinkratio_1','commonlinkratio_2','commonlinkratio_3','commonlinkratio_4', \n",
      "           'compression_ratio','embed_ratio','frameTagRatio', 'framebased', 'hasDomainLink', 'html_ratio', 'image_ratio', \n",
      "           'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks',\n",
      "           'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio']\n",
      "\n",
      "originalFeatures = df[originalFeatureList]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import TruncatedSVD\n",
      "\n",
      "titleDecomposed = TruncatedSVD(random_state = 123, n_components = 10).fit_transform(titleVect)\n",
      "bodyDecomposed = TruncatedSVD(random_state = 123, n_components = 50).fit_transform(bodyVect)\n",
      "\n",
      "textDecomposed = np.hstack([titleDecomposed,bodyDecomposed])\n",
      "textDecomposed_training = textDecomposed[df.setType == 'training']\n",
      "textDecomposed_test = textDecomposed[df.setType == 'test']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construct Training and Test Data\n",
      "originalFeatures_training = originalFeatures[df.setType == 'training']\n",
      "textFeatures_training = textFeatures[df.setType == 'training']\n",
      "domains_training = domains_df[df.setType == 'training']\n",
      "webNames_training = webNames_df[df.setType == 'training']\n",
      "numPaths_training = numPaths_df[df.setType == 'training']\n",
      "alchemyCategories_training = alchemyCategories_df[df.setType == 'training']\n",
      "\n",
      "Y = df[df.setType == 'training'].label\n",
      "X = np.concatenate((originalFeatures_training.values, textFeatures_training, numPaths_training,\n",
      "                    domains_training.values, webNames_training.values,alchemyCategories_training.values), 1)\n",
      "X[X == '?'] = 0\n",
      "\n",
      "\n",
      "# Construct ALTERNATE Training and Test Data\n",
      "X_alt = np.hstack([X, textDecomposed_training])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "originalFeatures_test = originalFeatures[df.setType == 'test']\n",
      "textFeatures_test = textFeatures[df.setType == 'test']\n",
      "domains_test = domains_df[df.setType == 'test']\n",
      "webNames_test = webNames_df[df.setType == 'test']\n",
      "numPaths_test = numPaths_df[df.setType == 'test']\n",
      "alchemyCategories_test = alchemyCategories_df[df.setType == 'test']\n",
      "\n",
      "X_Test = np.concatenate((originalFeatures_test.values, textFeatures_test, numPaths_test,\n",
      "                    domains_test.values, webNames_test.values,alchemyCategories_test.values), 1)\n",
      "X_Test[X_Test == '?'] = 0\n",
      "\n",
      "X_Test_alt = np.hstack([X_Test, textDecomposed_test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = pd.DataFrame(df[df.setType == 'test'].urlid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crossVal(clf, X_data, Y_data, NFOLDS = 10): \n",
      "    import sklearn.ensemble as ens\n",
      "    from sklearn import metrics\n",
      "    from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "    skf = StratifiedKFold(Y_data, n_folds = NFOLDS)\n",
      "    auc = []\n",
      "    for train_index, test_index in skf:\n",
      "        x_train, x_test = X_data[train_index], X_data[test_index]\n",
      "        y_train, y_test = Y_data[train_index], Y_data[test_index]\n",
      "        \n",
      "        clf.fit(x_train, y_train)\n",
      "        \n",
      "        try: \n",
      "            probs = clf.predict_proba(x_test)\n",
      "            y_hat = probs[:,1]\n",
      "        except:\n",
      "            y_hat = clf.predict(x_test)\n",
      "        auc.append(metrics.roc_auc_score(y_test, y_hat))\n",
      "    return auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elasticCV = ElasticNetCV(l1_ratio= [.1, .5, .7, .9, .95, .99, 1], n_jobs = 2)\n",
      "elasticCV.fit(X.astype(np.float),Y)\n",
      "alpha_star = elasticCV.alpha_\n",
      "l1_ratio_star = elasticCV.l1_ratio_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 237,
       "text": [
        "ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
        "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000,\n",
        "       n_alphas=100, n_jobs=1, normalize=False, precompute='auto',\n",
        "       tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# l1: 0.8, alpha = 1\n",
      "\n",
      "clf_EN_1 = ElasticNet(alpha = alpha_star, l1_ratio=l1_ratio_star)\n",
      "results = crossVal(clf_EN_1,X.astype(np.float),Y,10)\n",
      "print 'alpha: ' + str(alpha_star)\n",
      "print 'rho: ' + str(l1_ratio_star)\n",
      "print results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alpha: 0.589482653704\n",
        "rho: 0.1\n",
        "[0.62111842105263071, 0.6539254385964911, 0.62657163742690059, 0.64047514619882906, 0.59868421052631571, 0.62637056581647621, 0.62775579009088234, 0.65041776605101154, 0.57822486074464952, 0.6257147045887701]\n"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = RandomForestClassifier(criterion = 'gini',random_state = 123,\n",
      "                                 min_samples_leaf = 2, min_samples_split = 6, n_estimators = 300)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'LogisticRegression' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-19-28f6267c1ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m rf = RandomForestClassifier(criterion = 'gini',random_state = 123,\n\u001b[0;32m      2\u001b[0m                                  min_samples_leaf = 2, min_samples_split = 6, n_estimators = 300)\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr =  LogisticRegression(random_state = 123, penalty = 'l1', C = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.fit(X_alt, Y)\n",
      "lr.fit(X_alt, Y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'alt' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-22-a5e2a2773c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_alt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprobs_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Test_alt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprobs_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfinalPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprobs_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinalPrediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'alt' is not defined"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_rf = rf.predict_proba(X_Test_alt)[:,1]\n",
      "probs_lr = lr.predict_proba(X_Test_alt.astype(np.float))[:,1]\n",
      "finalPrediction = np.vstack([probs_rf, probs_lr]).mean(0)\n",
      "submission['label'] = finalPrediction.T\n",
      "submission.to_csv('submission_21.csv', index = False, sep = ',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train chosen classifier and predict on test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalPrediction = np.vstack([y_hat_GBM, y_hat_RF]).mean(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print RF_Best_alt_cv\n",
      "print np.mean(RF_Best_alt_cv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.86701754385964902, 0.85896929824561297, 0.88310672514619903, 0.87345760233918102, 0.86160818713450316, 0.89448841981823568, 0.86003371445323962, 0.87238346525945376, 0.8564057461155089, 0.85340126081219814]\n",
        "0.868087196318\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters3 = {'learning_rate': [0.05, 0.1, 0.25, 0.5, 0.75],\n",
      "              'n_estimators' : [100, 300, 500, 700, 1000, 2000, 4000],\n",
      "              'max_depth' : [2,3,4,5,10,15,20,50,100],\n",
      "              'min_samples_split' : [2,4,6,8,10],\n",
      "              'min_samples_leaf' : [1,2,5],\n",
      "              'subsample' : [0.5, 0.75, 1]}\n",
      "clfGBMGrid = GridSearchCV(GradientBoostingClassifier(random_state = 123), parameters3).fit(X,Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(random_state = 123, penalty = 'l1', C = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = crossVal(lr, X_alt.astype(np.float), Y, 10)\n",
      "print results\n",
      "print np.mean(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.86211257309941691, 0.8669809941520461, 0.88327485380117032, 0.88035087719298522, 0.85097953216374278, 0.88353855174435636, 0.86282615068894819, 0.877814423922603, 0.84919378481383645, 0.85499193666617901]\n",
        "0.867206367825\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = {'kernel':('linear','rbf', 'sigmoid', 'poly'), 'C':[1,10]}\n",
      "gridSVC = GridSearchCV(SVC(random_statez = 123), p).fit(X_alt, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC("
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gridLR = GridSearchCV(lr, param_grid = p, scoring='roc_auc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gridLR.fit(X_alt.astype(np.float))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "object of type 'NoneType' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-34-9588addf2e78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgridLR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_alt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/ben/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    705\u001b[0m                           \u001b[1;34m\" The params argument will be removed in 0.15.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                           DeprecationWarning)\n\u001b[1;32m--> 707\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/ben/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    472\u001b[0m                                  % (len(y), n_samples))\n\u001b[0;32m    473\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/ben/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1210\u001b[1;33m             \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mneeds_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/ben/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, indices, k)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}